import "dotenv/config"; import { Worker, Job } from "bullmq"; import ExcelJS from "exceljs"; import fs from "fs"; import prisma from "../config/prisma"; import { getIO } from "../lib/socket"; import IORedis from "ioredis"; import { InfluencerStatus, Prisma } from "@prisma/client"; const rawRedisUrl = process.env.REDIS_URL!; const connection = new IORedis(rawRedisUrl, { maxRetriesPerRequest: null }); interface ImportJobData { managerId: string; filePath: string; filename: string; importJobId: string; } const BATCH_SIZE = Number(process.env.IMPORT_BATCH_SIZE || 500); export const startImportWorker = () => { const worker = new Worker( "influencer-imports", async (job: Job<ImportJobData>) => { const { managerId, filePath, importJobId } = job.data; const io = (() => { try { return getIO(); } catch { return null; } })(); const emit = (payload: any) => { try { io?.to(manager:${managerId}).emit("import:progress", { jobId: importJobId, ...payload, }); } catch {} }; await prisma.importJob.update({ where: { id: importJobId }, data: { status: "PROCESSING" }, }); let processed = 0; let success = 0; let failed = 0; const errors: any[] = []; const duplicates: any[] = []; try { const workbookReader = new (ExcelJS as any).stream.xlsx.WorkbookReader( filePath, { entries: "emit", sharedStrings: "cache", hyperlinks: "emit", worksheets: "emit", } ); let headers: string[] | null = null; let buffer: any[] = []; const flush = async () => { if (!buffer.length) return; const emails = Array.from( new Set(buffer.map((r) => r.email).filter(Boolean)) ); const handles = Array.from( new Set(buffer.map((r) => r.instagramHandle).filter(Boolean)) ); const existing = await prisma.influencer.findMany({ where: { managerId, OR: [ emails.length ? { email: { in: emails } } : undefined, handles.length ? { instagramHandle: { in: handles } } : undefined, ].filter(Boolean) as any[], }, select: { id: true, email: true, instagramHandle: true }, }); const existingEmails = new Set( existing.map((e) => String(e.email).toLowerCase()).filter(Boolean) ); const existingHandles = new Set( existing .map((e) => String(e.instagramHandle).toLowerCase()) .filter(Boolean) ); const toInsert = buffer.filter((r) => { const em = r.email ? String(r.email).toLowerCase() : null; const handle = r.instagramHandle ? String(r.instagramHandle).toLowerCase() : null; if (em && existingEmails.has(em)) { duplicates.push({ email: r.email, handle: r.instagramHandle }); return false; } if (handle && existingHandles.has(handle)) { duplicates.push({ handle: r.instagramHandle, email: r.email }); return false; } return true; }); if (toInsert.length) { const mapped: Prisma.InfluencerCreateManyInput[] = toInsert.map( (r) => ({ name: r.name || r.instagramHandle || "Unknown", email: r.email || null, instagramHandle: r.instagramHandle || null, link: r.link || null, followers: typeof r.followers === "number" ? r.followers : null, country: r.country || null, notes: r.notes || null, status: InfluencerStatus.NOT_SENT, managerId, }) ); try { await prisma.influencer.createMany({ data: mapped, skipDuplicates: true, }); success += mapped.length; } catch (e: any) { for (const row of mapped) { try { await prisma.influencer.create({ data: row as any }); success++; } catch (innerErr: any) { failed++; errors.push({ row: row.email || row.instagramHandle, error: innerErr?.message ?? String(innerErr), }); } } } } buffer = []; await job.updateProgress({ processed, success, failed }); emit({ processed, success, failed, duplicatesCount: duplicates.length, }); }; for await (const worksheet of workbookReader) { for await (const row of worksheet) { const values = (row.values || []) as any[]; if (!headers) { headers = values .slice(1) .map((h: any) => (h ? String(h).trim().toLowerCase() : "")); continue; } processed++; const obj: any = {}; headers.forEach((h, idx) => { obj[h] = values[idx + 1] ?? null; }); const email = obj["email"] || obj["e-mail"] || obj["e_mail"] ? String(obj["email"] || obj["e-mail"] || obj["e_mail"]).trim() : null; const instagramHandle = obj["instagram"] || obj["instagram handle"] || obj["handle"] || obj["instagram_handle"] ? String( obj["instagram"] || obj["instagram handle"] || obj["handle"] || obj["instagram_handle"] ).trim() : null; const name = obj["name"] || obj["full name"] || obj["fullname"] ? String( obj["name"] || obj["full name"] || obj["fullname"] ).trim() : instagramHandle || null; const link = obj["link"] || obj["profile"] || obj["instagram url"] ? String( obj["link"] || obj["profile"] || obj["instagram url"] ).trim() : null; const followersRaw = obj["followers"] || obj["followers_count"]; const followers = followersRaw ? parseInt(String(followersRaw).replace(/\D/g, "")) || null : null; if (!email && !instagramHandle) { failed++; errors.push({ row: processed + 1, error: "Missing email and instagram handle", }); if (processed % 200 === 0) { await job.updateProgress({ processed, success, failed }); emit({ processed, success, failed, duplicatesCount: duplicates.length, }); } continue; } buffer.push({ name, email, instagramHandle, link, followers, country: obj["country"] || null, notes: obj["notes"] || null, }); if (buffer.length >= BATCH_SIZE) { await flush(); } if (processed % 200 === 0) { await job.updateProgress({ processed, success, failed }); emit({ processed, success, failed, duplicatesCount: duplicates.length, }); } } break; } if (buffer.length) await flush(); await prisma.importJob.update({ where: { id: importJobId }, data: { status: "COMPLETED", totalRows: processed, successCount: success, failedCount: failed, duplicates: duplicates.length ? (duplicates as Prisma.InputJsonValue) : undefined, errors: errors.length ? (errors as Prisma.InputJsonValue) : undefined, }, }); emit({ done: true, processed, success, failed, duplicatesCount: duplicates.length, }); try { fs.unlinkSync(filePath); } catch (e) {} return { processed, success, failed, duplicates, errors }; } catch (err: any) { await prisma.importJob.update({ where: { id: importJobId }, data: { status: "FAILED", errors: [ { error: err.message || String(err) }, ] as Prisma.InputJsonValue, }, }); emit({ error: err.message || String(err), failed: true }); try { fs.unlinkSync(filePath); } catch (e) {} throw err; } finally { try { await connection.quit(); } catch {} } }, { connection: connection as any, concurrency: Number(process.env.IMPORT_WORKER_CONCURRENCY || 1), } ); worker.on("failed", (job, err) => { console.error("[import.worker] job failed", job?.id, err); }); worker.on("completed", (job) => { console.log("[import.worker] job completed", job?.id); }); console.log("[import.worker] started"); return worker; }; Here is my current worker.ts: // src/worker.ts import "dotenv/config"; import redisQueue, { setupEventListeners } from "./lib/redis-queue"; (async () => { try { console.log("[worker] starting worker process..."); // optional: attach event listeners for logs/monitoring setupEventListeners(); // Defensive dynamic imports that work with ts-node / ESM / CJS const tryImport = async (p: string) => { try { const mod = await import(p); return mod; } catch (err) { console.warn([worker] dynamic import failed for ${p}, err); return null; } }; // Import both workers if present (don't crash if missing) const importWorkerModule = await tryImport("./workers/import.worker"); const exportWorkerModule = await tryImport("./workers/export.worker"); // Try to invoke both start functions if available const started: string[] = []; try { const startImport = importWorkerModule?.startImportWorker ?? importWorkerModule?.default; if (typeof startImport === "function") { startImport(); started.push("import.worker"); } } catch (e) { console.warn("[worker] failed to start import.worker:", e); } try { const startExport = exportWorkerModule?.startExportWorker ?? exportWorkerModule?.default; if (typeof startExport === "function") { startExport(); started.push("export.worker"); } } catch (e) { console.warn("[worker] failed to start export.worker:", e); } console.log("[worker] workers & schedulers initialized"); console.log( "[worker] listening for jobs on queues (email & follow-up) and:", started ); process.on("SIGINT", () => { console.log("[worker] SIGINT received, shutting down..."); process.exit(0); }); process.on("SIGTERM", () => { console.log("[worker] SIGTERM received, shutting down..."); process.exit(0); }); } catch (err) { console.error("[worker] failed to start:", err); process.exit(1); } })();